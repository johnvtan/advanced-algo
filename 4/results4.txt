Team Members: John Tan, Emerson Boyd

Our branch and bound algorithm for the knapsack problem branches on selecting or not selecting each item. The bound is calculated by adding items not yet branched on with the highest value/cost ratio to the knapsack until no more items can fit, then taking a fraction of the item with the next highest value/cost ratio to fill the remaining space. 

Our implementation starts by creating two partial solutions by branching on the first item. One partial solution has selected the first item, the other did not select the item. Then the upper bounds of each of these partial solutions are calculated and we explore the partial solution with the higher upper bound. We explore solutions depth-first by branching on each item, then greedily choosing whichever partial solution yields a higher upper bound. Partial solutions that are not explored immediately are stored in a list. Once we arrive at a complete solution (i.e., we have decided to select or not select every possible item), we compare it to our existing best solution. After we have arrived at a complete solution, we then search the entire list of partial solutions for the one with the highest upper bound. We repeat the procedure above for this solution and greedily explore it depth-first.

Once we arrive at a complete solution, we can begin pruning partial solutions. Any partial solution that has an upper bound that is less than or equal to the value of our best solution is removed from the list. Similarly, if we arrive at a complete solution whose value is worse than our current best solution, then that solution is thrown out. Otherwise, if the new complete solution has a greater value than our previous best, we update our best solution to be the new one.

Because this algorithm in the worst case has to search through every single possible solution, which is every possible subset of the items, it has an exponential worst-case runtime of O(2^n). However, due to the process of pruning partial solutions, it should on average have a lower runtime.

We will be comparing this algorithm's performance to other algorithms (exhaustive, greedy, and ILP). For smaller instances, B&B performs equally as well as exhaustive and ILP, as the same solutions are found equally quickly. As the input size increases, around size 64-128, B&B reaches the 10-minute limit. B&B performs better than exhaustive and greedy algorithms at this size, but ILP still reigns supreme. For example, at input size of 256: the greedy algorithm finds a value of 80043, the B&B algorithm finds a value of 80254, and ILP finds a value of 80605. Because ILP is professionaly optimized, it is not surprising that it has a slight advantage over our B&B algorithm.
